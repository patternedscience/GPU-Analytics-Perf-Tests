{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pandas perf tests\n",
    "### Loading financial time-series (per-minute ETFs) data from CSV files into a Pandas DF and running the queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data_path = '/workspace/data/datasets/unianalytica/group/analytics-perf-tests/symbols/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.Load up all files to one Pandas DF\n",
    "Takes about 2 minutes (63 files, 3.5 GB CSV format total size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now concatenating the DFs...\n"
     ]
    }
   ],
   "source": [
    "symbol_dfs_list = []\n",
    "records_count = 0\n",
    "symbols_files = sorted(os.listdir(data_path))\n",
    "for ix in range(len(symbols_files)):\n",
    "    current_symbol_df = pd.read_csv(data_path + symbols_files[ix], parse_dates=[2], infer_datetime_format=True,\n",
    "                                    names=['symbol_record_id', 'symbol', 'datetime', 'open', 'high', 'low', 'close', 'volume', 'split_factor', 'earnings', 'dividends'])\n",
    "    records_count = records_count + len(current_symbol_df)\n",
    "    symbol_dfs_list.append(current_symbol_df)\n",
    "    #print('Loaded symbol #{}'.format(ix+1))\n",
    "\n",
    "print('Now concatenating the DFs...')\n",
    "symbols_df = pd.concat(symbol_dfs_list)\n",
    "symbols_df.index = np.arange(records_count)\n",
    "del(symbol_dfs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Adding `symbol_id` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol_id</th>\n",
       "      <th>symbol_record_id</th>\n",
       "      <th>symbol</th>\n",
       "      <th>datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>split_factor</th>\n",
       "      <th>earnings</th>\n",
       "      <th>dividends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>aaxj</td>\n",
       "      <td>2008-08-15 12:44:00</td>\n",
       "      <td>43.07</td>\n",
       "      <td>43.07</td>\n",
       "      <td>43.07</td>\n",
       "      <td>43.07</td>\n",
       "      <td>232.759</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>aaxj</td>\n",
       "      <td>2008-08-15 16:00:00</td>\n",
       "      <td>43.07</td>\n",
       "      <td>43.07</td>\n",
       "      <td>43.07</td>\n",
       "      <td>43.07</td>\n",
       "      <td>116.379</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>aaxj</td>\n",
       "      <td>2008-08-18 09:28:00</td>\n",
       "      <td>42.63</td>\n",
       "      <td>42.75</td>\n",
       "      <td>42.63</td>\n",
       "      <td>42.75</td>\n",
       "      <td>10143.600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>aaxj</td>\n",
       "      <td>2008-08-18 09:30:00</td>\n",
       "      <td>42.77</td>\n",
       "      <td>42.77</td>\n",
       "      <td>42.77</td>\n",
       "      <td>42.77</td>\n",
       "      <td>24439.700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>aaxj</td>\n",
       "      <td>2008-08-18 10:07:00</td>\n",
       "      <td>42.53</td>\n",
       "      <td>42.53</td>\n",
       "      <td>42.53</td>\n",
       "      <td>42.53</td>\n",
       "      <td>2327.590</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   symbol_id  symbol_record_id symbol            datetime   open   high  \\\n",
       "0          1                 0   aaxj 2008-08-15 12:44:00  43.07  43.07   \n",
       "1          1                 1   aaxj 2008-08-15 16:00:00  43.07  43.07   \n",
       "2          1                 2   aaxj 2008-08-18 09:28:00  42.63  42.75   \n",
       "3          1                 3   aaxj 2008-08-18 09:30:00  42.77  42.77   \n",
       "4          1                 4   aaxj 2008-08-18 10:07:00  42.53  42.53   \n",
       "\n",
       "     low  close     volume  split_factor  earnings  dividends  \n",
       "0  43.07  43.07    232.759           1.0       0.0        0.0  \n",
       "1  43.07  43.07    116.379           1.0       0.0        0.0  \n",
       "2  42.63  42.75  10143.600           1.0       0.0        0.0  \n",
       "3  42.77  42.77  24439.700           1.0       0.0        0.0  \n",
       "4  42.53  42.53   2327.590           1.0       0.0        0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols_list = sorted(pd.unique(symbols_df.symbol))\n",
    "keys = symbols_list\n",
    "values = list(range(1, len(symbols_list)+1))\n",
    "dictionary = dict(zip(keys, values))\n",
    "symbols_df.insert(0, 'symbol_id', np.array([dictionary[x] for x in symbols_df.symbol.values]))\n",
    "symbols_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.Perf Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 2.1 Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trading volume stats: mean of 11881.69967593782, variance of 10852793799.402876\n",
      "Trading volume stats: mean of 11881.69967593782, variance of 10852793799.402876\n",
      "Trading volume stats: mean of 11881.69967593782, variance of 10852793799.402876\n",
      "673 ms ± 1.13 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r3\n",
    "print('Trading volume stats: mean of {}, variance of {}'.format(symbols_df['volume'].mean(), symbols_df['volume'].var()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 2.2 Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41 Timestamp('2008-11-21 16:00:00') 116022000.0]\n",
      "[41 Timestamp('2008-11-21 16:00:00') 116022000.0]\n",
      "[41 Timestamp('2008-11-21 16:00:00') 116022000.0]\n",
      "15.1 s ± 130 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r3\n",
    "symbols_df_sorted = symbols_df[['symbol_id', 'datetime', 'volume']].sort_values(by='volume', ascending=False)\n",
    "print(symbols_df_sorted.iloc[0].values)\n",
    "# Should not sort the DF inplace to avoid skewing the results for subsequent runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 2.3 Mixed analytics (math ops + sorting) [finding the top per-minute return]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          symbol_id            datetime     return\n",
      "33060823         46 2010-05-06 17:23:00  22.580645\n",
      "          symbol_id            datetime     return\n",
      "33060823         46 2010-05-06 17:23:00  22.580645\n",
      "          symbol_id            datetime     return\n",
      "33060823         46 2010-05-06 17:23:00  22.580645\n",
      "10.7 s ± 1.33 s per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r3\n",
    "symbols_df['return'] = 100*(symbols_df['close']-symbols_df['open'])/symbols_df['open']\n",
    "print(symbols_df[['symbol_id', 'datetime', 'return']].sort_values(by='return', ascending=False).head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Copyright (c) 2019, PatternedScience Inc.\n",
    "\n",
    "This code was originally run on the [UniAnalytica](https://www.unianalytica.com) platform, is published by PatternedScience Inc. on [GitHub](https://github.com/patternedscience/GPU-Analytics-Perf-Tests) and is licensed under the terms of Apache License 2.0; a copy of the license is available in the GitHub repository."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
