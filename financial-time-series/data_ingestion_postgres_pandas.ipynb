{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to load financial time-series (per-minute ETFs) data from CSV files into a Pandas DF and a Postgres table\n",
    "### The ingestion for Pandas is also done in its own perf tests notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/workspace/data/datasets/unianalytica/group/analytics-perf-tests/symbols/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Load up all files to one Pandas DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now concatenating the DFs...\n"
     ]
    }
   ],
   "source": [
    "symbol_dfs_list = []\n",
    "records_count = 0\n",
    "symbols_files = sorted(os.listdir(data_path))\n",
    "for ix in range(len(symbols_files)):\n",
    "    current_symbol_df = pd.read_csv(data_path + symbols_files[ix], parse_dates=[2], infer_datetime_format=True,\n",
    "                                    names=['symbol_record_id', 'symbol', 'datetime', 'open', 'high', 'low', 'close', 'volume', 'split_factor', 'earnings', 'dividends'])\n",
    "    records_count = records_count + len(current_symbol_df)\n",
    "    symbol_dfs_list.append(current_symbol_df)\n",
    "    #print('Loaded symbol #{}'.format(ix+1))\n",
    "\n",
    "print('Now concatenating the DFs...')\n",
    "symbols_df = pd.concat(symbol_dfs_list)\n",
    "symbols_df.index = np.arange(records_count)\n",
    "del(symbol_dfs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding `symbol_id` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol_id</th>\n",
       "      <th>symbol_record_id</th>\n",
       "      <th>symbol</th>\n",
       "      <th>datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>split_factor</th>\n",
       "      <th>earnings</th>\n",
       "      <th>dividends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>aaxj</td>\n",
       "      <td>2008-08-15 12:44:00</td>\n",
       "      <td>43.07</td>\n",
       "      <td>43.07</td>\n",
       "      <td>43.07</td>\n",
       "      <td>43.07</td>\n",
       "      <td>232.759</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>aaxj</td>\n",
       "      <td>2008-08-15 16:00:00</td>\n",
       "      <td>43.07</td>\n",
       "      <td>43.07</td>\n",
       "      <td>43.07</td>\n",
       "      <td>43.07</td>\n",
       "      <td>116.379</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>aaxj</td>\n",
       "      <td>2008-08-18 09:28:00</td>\n",
       "      <td>42.63</td>\n",
       "      <td>42.75</td>\n",
       "      <td>42.63</td>\n",
       "      <td>42.75</td>\n",
       "      <td>10143.600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>aaxj</td>\n",
       "      <td>2008-08-18 09:30:00</td>\n",
       "      <td>42.77</td>\n",
       "      <td>42.77</td>\n",
       "      <td>42.77</td>\n",
       "      <td>42.77</td>\n",
       "      <td>24439.700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>aaxj</td>\n",
       "      <td>2008-08-18 10:07:00</td>\n",
       "      <td>42.53</td>\n",
       "      <td>42.53</td>\n",
       "      <td>42.53</td>\n",
       "      <td>42.53</td>\n",
       "      <td>2327.590</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   symbol_id  symbol_record_id symbol            datetime   open   high  \\\n",
       "0          1                 0   aaxj 2008-08-15 12:44:00  43.07  43.07   \n",
       "1          1                 1   aaxj 2008-08-15 16:00:00  43.07  43.07   \n",
       "2          1                 2   aaxj 2008-08-18 09:28:00  42.63  42.75   \n",
       "3          1                 3   aaxj 2008-08-18 09:30:00  42.77  42.77   \n",
       "4          1                 4   aaxj 2008-08-18 10:07:00  42.53  42.53   \n",
       "\n",
       "     low  close     volume  split_factor  earnings  dividends  \n",
       "0  43.07  43.07    232.759           1.0       0.0        0.0  \n",
       "1  43.07  43.07    116.379           1.0       0.0        0.0  \n",
       "2  42.63  42.75  10143.600           1.0       0.0        0.0  \n",
       "3  42.77  42.77  24439.700           1.0       0.0        0.0  \n",
       "4  42.53  42.53   2327.590           1.0       0.0        0.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols_list = sorted(pd.unique(symbols_df.symbol))\n",
    "keys = symbols_list\n",
    "values = list(range(1, len(symbols_list)+1))\n",
    "dictionary = dict(zip(keys, values))\n",
    "symbols_df.insert(0, 'symbol_id', np.array([dictionary[x] for x in symbols_df.symbol.values]))\n",
    "symbols_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Import all files to a single table in the tests DB on Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols_files = sorted(os.listdir(data_path))\n",
    "keys = symbols_files\n",
    "values = list(range(1, len(symbols_files)+1))\n",
    "dictionary = dict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn = psycopg2.connect(dbname='tests', user='hitchhiker', host='localhost', password='freeride', port='9478')\n",
    "except:\n",
    "    print('I am unable to connect to the database')\n",
    "    \n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlQuery = '''\n",
    "DROP TABLE IF EXISTS public.symbols_minute;\n",
    "\n",
    "DROP TABLE IF EXISTS public.symbols_minute_staging;\n",
    "'''\n",
    "cur.execute(sqlQuery)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlQuery = '''\n",
    "CREATE TABLE public.symbols_minute\n",
    "(\n",
    "  symbol_id int,\n",
    "  symbol_record_id int,\n",
    "  symbol character varying(4),\n",
    "  datetime timestamp without time zone NOT NULL,\n",
    "  open real,\n",
    "  high real,\n",
    "  low real,\n",
    "  close real,\n",
    "  volume real,\n",
    "  split_factor real,\n",
    "  earnings real,\n",
    "  dividends real\n",
    ");\n",
    "\n",
    "CREATE INDEX symbols_minute_datetime_idx ON public.symbols_minute (datetime);\n",
    "'''\n",
    "cur.execute(sqlQuery)\n",
    "conn.commit()\n",
    "    \n",
    "sqlQuery = '''\n",
    "CREATE TABLE public.symbols_minute_staging\n",
    "(\n",
    "  symbol_record_id int,\n",
    "  symbol character varying(4),\n",
    "  datetime timestamp without time zone PRIMARY KEY NOT NULL,\n",
    "  open real,\n",
    "  high real,\n",
    "  low real,\n",
    "  close real,\n",
    "  volume real,\n",
    "  split_factor real,\n",
    "  earnings real,\n",
    "  dividends real\n",
    ");\n",
    "'''\n",
    "cur.execute(sqlQuery)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713747 records from aaxj.csv are imported\n",
      "740226 records from acwi.csv are imported\n",
      "1176236 records from agg.csv are imported\n",
      "744534 records from agq.csv are imported\n",
      "97408 records from bal.csv are imported\n",
      "209734 records from bik.csv are imported\n",
      "724294 records from biv.csv are imported\n",
      "311684 records from bkf.csv are imported\n",
      "971145 records from bnd.csv are imported\n",
      "329759 records from brf.csv are imported\n",
      "897540 records from bsv.csv are imported\n",
      "613534 records from bwx.csv are imported\n",
      "801695 records from csj.csv are imported\n",
      "151729 records from dag.csv are imported\n",
      "911223 records from dba.csv are imported\n",
      "396196 records from dbb.csv are imported\n",
      "1120318 records from dbc.csv are imported\n",
      "222477 records from dbe.csv are imported\n",
      "596675 records from dbo.csv are imported\n",
      "965754 records from ddm.csv are imported\n",
      "686974 records from dem.csv are imported\n",
      "738617 records from dgaz.csv are imported\n",
      "540873 records from dgp.csv are imported\n",
      "447393 records from dgs.csv are imported\n",
      "2205551 records from dia.csv are imported\n",
      "766858 records from dig.csv are imported\n",
      "706549 records from djp.csv are imported\n",
      "750583 records from dog.csv are imported\n",
      "550154 records from drn.csv are imported\n",
      "422018 records from drv.csv are imported\n",
      "465337 records from dto.csv are imported\n",
      "792790 records from dug.csv are imported\n",
      "876324 records from dust.csv are imported\n",
      "1339492 records from dvy.csv are imported\n",
      "1106553 records from dxd.csv are imported\n",
      "443106 records from dzz.csv are imported\n",
      "522919 records from ech.csv are imported\n",
      "880975 records from edc.csv are imported\n",
      "861640 records from edz.csv are imported\n",
      "397302 records from eeb.csv are imported\n",
      "1636423 records from eem.csv are imported\n",
      "578232 records from eev.csv are imported\n",
      "1586562 records from efa.csv are imported\n",
      "798735 records from emb.csv are imported\n",
      "111377 records from eny.csv are imported\n",
      "941161 records from epi.csv are imported\n",
      "1063864 records from epp.csv are imported\n",
      "308303 records from epu.csv are imported\n",
      "1015647 records from erx.csv are imported\n",
      "910479 records from ery.csv are imported\n",
      "379833 records from eum.csv are imported\n",
      "636708 records from euo.csv are imported\n",
      "1221628 records from ewa.csv are imported\n",
      "1221855 records from ewc.csv are imported\n",
      "612191 records from ewd.csv are imported\n",
      "1217676 records from ewg.csv are imported\n",
      "1306387 records from ewh.csv are imported\n",
      "1707118 records from ewj.csv are imported\n",
      "724760 records from ewl.csv are imported\n",
      "1087538 records from ewm.csv are imported\n",
      "757775 records from ewp.csv are imported\n",
      "1104913 records from ews.csv are imported\n",
      "1343489 records from ewt.csv are imported\n",
      "Data import finished.\n"
     ]
    }
   ],
   "source": [
    "num_files = 0\n",
    "for ix in range(len(symbols_files)):\n",
    "    num_files += 1\n",
    "    #if num_files > 2: break\n",
    "    try:\n",
    "        cur.execute(\"TRUNCATE TABLE public.symbols_minute_staging;\")\n",
    "        conn.commit()\n",
    "\n",
    "        f = open(data_path + symbols_files[ix], 'r')\n",
    "        cur.copy_from(f, 'symbols_minute_staging', sep=',')\n",
    "        conn.commit()\n",
    "\n",
    "        sqlQuery = '''\n",
    "        SELECT COUNT(*)\n",
    "        FROM public.symbols_minute_staging;\n",
    "        '''\n",
    "        cur.execute(sqlQuery)\n",
    "        current_count = cur.fetchall()[0][0]\n",
    "        \n",
    "        sqlQuery = '''\n",
    "        INSERT INTO symbols_minute\n",
    "        SELECT '%(symbol_id)s', *\n",
    "        FROM public.symbols_minute_staging;\n",
    "        '''% {'symbol_id': dictionary[symbols_files[ix]]}\n",
    "        cur.execute(sqlQuery)\n",
    "        conn.commit()\n",
    "        \n",
    "        print('{} records from {} are imported'.format(current_count, symbols_files[ix]))\n",
    "    except:\n",
    "        print('Cound not import ' + symbols_files[ix])\n",
    "        e = sys.exc_info()[0]\n",
    "        print(\"Error: %s\" % e)\n",
    "            \n",
    "print('Data import finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50470570\n",
      "(1, 0, 'aaxj', datetime.datetime(2008, 8, 15, 12, 44), 43.07, 43.07, 43.07, 43.07, 232.759, 1.0, 0.0, 0.0)\n",
      "(1, 1, 'aaxj', datetime.datetime(2008, 8, 15, 16, 0), 43.07, 43.07, 43.07, 43.07, 116.379, 1.0, 0.0, 0.0)\n",
      "(1, 2, 'aaxj', datetime.datetime(2008, 8, 18, 9, 28), 42.63, 42.75, 42.63, 42.75, 10143.6, 1.0, 0.0, 0.0)\n",
      "(1, 3, 'aaxj', datetime.datetime(2008, 8, 18, 9, 30), 42.77, 42.77, 42.77, 42.77, 24439.7, 1.0, 0.0, 0.0)\n",
      "(1, 4, 'aaxj', datetime.datetime(2008, 8, 18, 10, 7), 42.53, 42.53, 42.53, 42.53, 2327.59, 1.0, 0.0, 0.0)\n",
      "(1, 5, 'aaxj', datetime.datetime(2008, 8, 18, 10, 43), 42.4, 42.4, 42.4, 42.4, 2327.59, 1.0, 0.0, 0.0)\n",
      "(1, 6, 'aaxj', datetime.datetime(2008, 8, 18, 10, 53), 42.4, 42.4, 42.4, 42.4, 2327.59, 1.0, 0.0, 0.0)\n",
      "(1, 7, 'aaxj', datetime.datetime(2008, 8, 18, 12, 4), 42.24, 42.24, 42.23, 42.23, 232.759, 1.0, 0.0, 0.0)\n",
      "(1, 8, 'aaxj', datetime.datetime(2008, 8, 18, 12, 44), 42.1, 42.1, 42.1, 42.1, 116.379, 1.0, 0.0, 0.0)\n",
      "(1, 9, 'aaxj', datetime.datetime(2008, 8, 18, 16, 0), 42.1, 42.1, 42.1, 42.1, 116.379, 1.0, 0.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT count(*) FROM public.symbols_minute;\")\n",
    "print(cur.fetchall()[0][0])\n",
    "    \n",
    "cur.execute(\"SELECT * FROM public.symbols_minute LIMIT 10;\")\n",
    "for row in cur.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2019, PatternedScience Inc.\n",
    "\n",
    "This code was originally run on the [UniAnalytica](https://www.unianalytica.com) platform, is published by PatternedScience Inc. on [GitHub](https://github.com/patternedscience/GPU-Analytics-Perf-Tests) and is licensed under the terms of Apache License 2.0; a copy of the license is available in the GitHub repository."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cpu_df]",
   "language": "python",
   "name": "conda-env-cpu_df-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
